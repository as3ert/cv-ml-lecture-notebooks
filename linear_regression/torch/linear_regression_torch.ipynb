{"cells":[{"cell_type":"markdown","metadata":{"id":"epxcwtWj5yJs"},"source":["# Linear regression in PyTorch\n","\n","Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n","\n","This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."]},{"cell_type":"markdown","metadata":{"id":"IJsjl_l47q28"},"source":["## Setup\n","\n","Adapt `packagePath` to point to the directory containing this notebeook."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1703326573912,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"1iHkPBml98YG"},"outputs":[],"source":["# Imports\n","import sys\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2602,"status":"ok","timestamp":1703326576880,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"DY4880S378_F","outputId":"a8ce2d26-fe24-4aa2-c232-acc31b71d394"},"outputs":[],"source":["# Package Path\n","package_path = \"./\" # local\n","\n","# Colab specific stuff below.\n","# If you use Colab, change package_path to a path on your Google drive\n","\n","def check_for_colab():\n","  try:\n","      import google.colab\n","      return True\n","  except ImportError:\n","      return False\n","\n","# Running on Colab?\n","on_colab = check_for_colab()\n","\n","# Google drive mount point\n","gdrive_mnt = '/content/drive'\n","\n","# Mount Google Drive if on Colab\n","if on_colab:\n","  from google.colab import drive\n","  drive.mount(gdrive_mnt, force_remount=True)\n","  package_path = f\"{gdrive_mnt}/MyDrive/colab/lecture_examples/cv-ml-lecture-notebooks/linear_regression/torch\"   # Colab\n","\n","\n","print(f\"Package path: {package_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6888,"status":"ok","timestamp":1703326583765,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"iaURjw5n6pLq","outputId":"5c40ee52-1fa3-44df-a94e-b81bec144100"},"outputs":[],"source":["# Install requirements in the current Jupyter kernel\n","req_file = os.path.join(package_path, \"requirements.txt\")\n","if os.path.exists(req_file):\n","    !{sys.executable} -m pip install -r {req_file}\n","else:\n","    print(f\"Requirements file not found: {req_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1703326583765,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"iRERDI8aAnzr"},"outputs":[],"source":["# Now we should be able to import the additional packages\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Set the random seed for reproducibility\n","torch.manual_seed(42);\n"]},{"cell_type":"markdown","metadata":{"id":"aUACL9QoFTXg"},"source":["## Linear regression"]},{"cell_type":"markdown","metadata":{},"source":["### Create some data based on adding noise to a known linear function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating a function f(x) with a slope of 2 and bias of 1, e.g. f(x) = 2x + 1\n","# and added Gaussian noise\n","\n","# True parameters\n","w_true = 2\n","b_true = 1\n","params_true = torch.tensor([w_true, b_true])\n","\n","X = torch.arange(-5, 5, 0.1)\n","Y = w_true*X + b_true + 2 * torch.randn(X.shape)\n","\n","# Visualize\n","plt.scatter(X, Y, alpha=0.5)\n","plt.title(\"Scatter plot of f(x) = 2x + 1 + Gaussian noise\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Linear model and loss\n","\n","Our linear regression model is $ y = f(x) = w \\cdot x + b$. We solve for $w$ and $b$ using gradient descent. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def lin_model(params, x):\n","    w,b = params\n","    return w*x + b"]},{"cell_type":"markdown","metadata":{},"source":["We uses mean squared error loss between the predictions of our model and true values. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def loss_fn(y_pred, y):   \n","    return torch.mean(torch.square(y - y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["### Optimization via gradient descent"]},{"cell_type":"markdown","metadata":{},"source":["Initialize parameters $w$ and $b$ randomly."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["params = 1e-2 * torch.randn(2, dtype=torch.float32)\n","\n","# we track gradients for the parameters w and b\n","params.requires_grad_()\n","\n","w,b = params\n","print(f\"Initial weight : {w}\")\n","print(f\"Initial bias   : {b}\")"]},{"cell_type":"markdown","metadata":{},"source":["Optimize via gradient descent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hyperparameters\n","num_iters = 10000\n","learning_rate = 3e-4\n","\n","# Loop over the number of iterations\n","for it in range(num_iters):\n","\n","    # predict y from x\n","    Y_pred = lin_model(params, X)\n","\n","    # Compute the loss\n","    loss = loss_fn(Y_pred, Y)\n","\n","    # Gradient of loss function w.r.t parameters\n","    loss.backward()\n","  \n","    # update parameters via gradient descent update rules\n","    with torch.no_grad():\n","        params -= learning_rate * params.grad\n","        params.grad.zero_()\n","  \n","    # Give some status output once in a while\n","    if it % 500 == 0 or it == num_iters - 1:\n","        w,b = params  \n","        error_norm = torch.sum(torch.square(params - params_true)) ** 0.5\n","        print(f\"Iteration {it:5d} | Loss {loss.item():>10.5f} | \" \n","              f\"w {w.item():> 8.5f} | b {b.item():> 8.5f} | Error norm {error_norm.item():>.5f}\")\n","    \n","w,b = params    \n","print(f\"Final weight after optimization : {w.item():.5f} (true: {w_true})\")\n","print(f\"Final bias after optimization   : {b.item():.5f} (true: {b_true})\")       "]},{"cell_type":"markdown","metadata":{},"source":["Visualize linear fit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize\n","plt.scatter(X, Y, alpha=0.5)\n","plt.title(\"Scatter plot of f(x) = 2x + 1 + Gaussian noise\")\n","\n","# Plot the recovered line\n","Y_model = lin_model(params, X)\n","plt.plot(X.tolist(), Y_model.tolist(), color='red')\n","\n","plt.legend([\"data\", f\"f(x) = {w.item():.3f}x + {b.item():.3f}\"])\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["JcF1mpJo-taz"],"provenance":[]},"kernelspec":{"display_name":"pytorch-m1-2023-10","language":"python","name":"pytorch-m1-2023-10"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
