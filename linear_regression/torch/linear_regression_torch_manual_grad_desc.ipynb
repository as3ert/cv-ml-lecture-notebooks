{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epxcwtWj5yJs"
   },
   "source": [
    "# Linear regression in PyTorch with manual gradient descent\n",
    "\n",
    "Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n",
    "\n",
    "This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJsjl_l47q28"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Adapt `packagePath` to point to the directory containing this notebeook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1703326573912,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "1iHkPBml98YG"
   },
   "outputs": [],
   "source": [
    "# Notebook id\n",
    "nb_id = \"linear_regression/torch\"\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Path (folder of this notebook)\n",
    "\n",
    "#####################\n",
    "# Local environment #\n",
    "#####################\n",
    "\n",
    "package_path = \"./\"\n",
    "\n",
    "\n",
    "#########\n",
    "# Colab #\n",
    "#########\n",
    "\n",
    "\n",
    "def check_for_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# running on Colab?\n",
    "on_colab = check_for_colab()\n",
    "\n",
    "if on_colab:\n",
    "    # assume this notebook is run from Google Drive and the whole\n",
    "    # cv-ml-lecture-notebooks repo has been setup via setupOnColab.ipynb\n",
    "\n",
    "    # Google Drive mount point\n",
    "    gdrive_mnt = \"/content/drive\"\n",
    "\n",
    "    ##########################################################################\n",
    "    # Ensure that this is the same as gdrive_repo_root in setupOnColab.ipynb #\n",
    "    ##########################################################################\n",
    "    # Path on Google Drive to the cv-ml-lecture-notebooks repo\n",
    "    gdrive_repo_root = f\"{gdrive_mnt}/MyDrive/cv-ml-lecture-notebooks\"\n",
    "\n",
    "    # mount drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(gdrive_mnt, force_remount=True)\n",
    "\n",
    "    # set package path\n",
    "    package_path = f\"{gdrive_repo_root}/{nb_id}\"\n",
    "\n",
    "# check whether package path exists\n",
    "if not os.path.isdir(package_path):\n",
    "    raise FileNotFoundError(f\"Package path does not exist: {package_path}\")\n",
    "\n",
    "print(f\"Package path: {package_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2602,
     "status": "ok",
     "timestamp": 1703326576880,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "DY4880S378_F",
    "outputId": "a8ce2d26-fe24-4aa2-c232-acc31b71d394"
   },
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "\n",
    "# Repository Root\n",
    "repo_root = os.path.abspath(os.path.join(package_path, \"..\", \"..\"))\n",
    "# Add the repository root to the system path\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "# Package Imports\n",
    "from nbutils import requirements as nb_reqs\n",
    "from nbutils import colab as nb_colab\n",
    "from nbutils import git as nb_git\n",
    "from nbutils import exec as nb_exec\n",
    "from nbutils import data as nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6888,
     "status": "ok",
     "timestamp": 1703326583765,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "iaURjw5n6pLq",
    "outputId": "5c40ee52-1fa3-44df-a94e-b81bec144100"
   },
   "outputs": [],
   "source": [
    "# Install requirements in the current Jupyter kernel\n",
    "req_file = os.path.join(package_path, \"requirements.txt\")\n",
    "nb_reqs.pip_install_reqs(req_file, on_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1703326583765,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "iRERDI8aAnzr"
   },
   "outputs": [],
   "source": [
    "# Now we should be able to import the additional packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUACL9QoFTXg"
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some data based on adding noise to a known linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function f(x) with a slope of 2 and bias of 1, e.g. f(x) = 2x + 1\n",
    "# and added Gaussian noise\n",
    "\n",
    "# True parameters\n",
    "w_true = 2\n",
    "b_true = 1\n",
    "\n",
    "X = torch.arange(-5, 5, 0.1)\n",
    "Y = w_true * X + b_true + 2 * torch.randn(X.shape)\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X, Y, alpha=0.5)\n",
    "plt.title(\"Scatter plot of f(x) = 2x + 1 + Gaussian noise\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model and loss\n",
    "\n",
    "Our linear regression model is $ y = f(x) = w \\cdot x + b$. We solve for $w$ and $b$ using gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_model(w, b, x):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We uses mean squared error loss between the predictions $\\hat{y_i}$ of our model and true values $y_i$:\n",
    "\n",
    "$$L(w,b) = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2= \\frac{1}{N} \\sum_{i=1}^{N} (y_i - (w \\cdot x_i + b))^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y):\n",
    "    return torch.mean(torch.square(y - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization via gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients of the loss $L(w,b)$ with respect to both $w$ and $b$ are (application of chain rule):\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{1}{N} \\sum_{i=1}^{N} 2(y_i - (w \\cdot x_i + b)) \\cdot \\frac{\\partial}{\\partial w} (y_i - (w  \\cdot x_i + b))$$\n",
    "\n",
    "$$ = \\frac{1}{N} \\sum_{i=1}^{N} 2(y_i - (w \\cdot  x_i + b)) \\cdot (-x_i)$$ \n",
    "\n",
    "$$ = \\frac{1}{N} \\sum_{i=1}^{N} -2(y_i - w \\cdot x_i - b) \\cdot x_i$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^{N} 2(y_i - (w \\cdot x_i + b)) \\cdot \\frac{\\partial}{\\partial b} (y_i - (w \\cdot x_i + b))$$\n",
    "\n",
    "$$ = \\frac{1}{N} \\sum_{i=1}^{N} 2(y_i - (w \\cdot x_i + b)) \\cdot (-b)$$\n",
    "\n",
    "$$ = \\frac{1}{N} \\sum_{i=1}^{N} -2(y_i - w \\cdot x_i - b)$$\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss_w(x, y, w, b):\n",
    "    return torch.mean(-2 * (y - w*x -b) * x)\n",
    "\n",
    "def grad_loss_b(x, y, w, b):\n",
    "    return torch.mean(-2 * (y - w*x -b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters $w$ and $b$ randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1e-2 * torch.randn(1, dtype=torch.float32)\n",
    "b = 1e-2 * torch.randn(1, dtype=torch.float32)\n",
    "\n",
    "print(f\"Initial weight : {w}\")\n",
    "print(f\"Initial bias   : {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize via gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_iters = 10000\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Loop over the number of iterations\n",
    "for it in range(num_iters):\n",
    "\n",
    "    # predict y from x\n",
    "    Y_pred = lin_model(w, b, X)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(Y_pred, Y)\n",
    "\n",
    "    # Gradient of loss function w.r.t parameters\n",
    "    grad_w = grad_loss_w(X, Y, w, b)\n",
    "    grad_b = grad_loss_b(X, Y, w, b)\n",
    "\n",
    "    # update parameters via gradient descent update rules\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * grad_w\n",
    "        b -= learning_rate * grad_b\n",
    "\n",
    "    # Give some status output once in a while\n",
    "    if it % 500 == 0 or it == num_iters - 1:      \n",
    "        print(\n",
    "            f\"Iteration {it:5d} | Loss {loss.item():>10.5f} | \"\n",
    "            f\"w {w.item():> 8.5f} | b {b.item():> 8.5f}\"\n",
    "        )\n",
    "\n",
    "print(f\"Final weight after optimization : {w.item():.5f} (true: {w_true})\")\n",
    "print(f\"Final bias after optimization   : {b.item():.5f} (true: {b_true})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize linear fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.scatter(X, Y, alpha=0.5)\n",
    "plt.title(\"Scatter plot of f(x) = 2x + 1 + Gaussian noise\")\n",
    "\n",
    "# Plot the recovered line\n",
    "Y_model = lin_model(w, b, X)\n",
    "plt.plot(X.tolist(), Y_model.tolist(), color=\"red\")\n",
    "\n",
    "plt.legend([\"data\", f\"f(x) = {w.item():.3f}x + {b.item():.3f}\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JcF1mpJo-taz"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlx-pytorch-2024-01",
   "language": "python",
   "name": "mlx-pytorch-2024-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
