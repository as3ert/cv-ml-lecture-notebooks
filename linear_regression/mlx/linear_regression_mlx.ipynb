{"cells":[{"cell_type":"markdown","metadata":{"id":"epxcwtWj5yJs"},"source":["# Linear regression in MLX\n","\n","Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n","\n","This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute.\n","\n","**Note: This requires a machine with an Apple SoC, e.g. M1/M2/M3 etc.**\n","\n","See: https://github.com/ml-explore/mlx\n"]},{"cell_type":"markdown","metadata":{"id":"IJsjl_l47q28"},"source":["## Setup\n","\n","Adapt `packagePath` to point to the directory containing this notebeook."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1703326573912,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"1iHkPBml98YG"},"outputs":[],"source":["# Notebook id\n","nb_id = \"linear_regression/mlx\"\n","\n","# Imports\n","import sys\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Package Path (folder of this notebook)\n","\n","#####################\n","# Local environment #\n","#####################\n","\n","package_path = \"./\"\n","\n","\n","#########\n","# Colab #\n","#########\n","\n","\n","def check_for_colab():\n","  try:\n","      import google.colab\n","      return True\n","  except ImportError:\n","      return False\n","\n","# running on Colab?\n","on_colab = check_for_colab()\n","\n","if on_colab:\n","\n","    # assume this notebook is run from Google Drive and the whole\n","    # cv-ml-lecture-notebooks repo has been setup via setupOnColab.ipynb\n","\n","    # Google Drive mount point\n","    gdrive_mnt = '/content/drive'\n","\n","    ##########################################################################\n","    # Ensure that this is the same as gdrive_repo_root in setupOnColab.ipynb #\n","    ##########################################################################\n","    # Path on Google Drive to the cv-ml-lecture-notebooks repo\n","    gdrive_repo_root = f\"{gdrive_mnt}/MyDrive/cv-ml-lecture-notebooks\"\n","\n","    # mount drive\n","    from google.colab import drive\n","    drive.mount(gdrive_mnt, force_remount=True)\n","\n","    # set package path\n","    package_path = f\"{gdrive_repo_root}/{nb_id}\"\n","\n","# check whether package path exists\n","if not os.path.isdir(package_path):\n","  raise FileNotFoundError(f\"Package path does not exist: {package_path}\")\n","\n","print(f\"Package path: {package_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2602,"status":"ok","timestamp":1703326576880,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"DY4880S378_F","outputId":"a8ce2d26-fe24-4aa2-c232-acc31b71d394"},"outputs":[],"source":["# Additional imports\n","\n","# Repository Root\n","repo_root = os.path.abspath(os.path.join(package_path, \"..\", \"..\"))\n","# Add the repository root to the system path\n","if repo_root not in sys.path:\n","    sys.path.append(repo_root)\n","\n","# Package Imports\n","from nbutils import requirements as nb_reqs\n","from nbutils import colab as nb_colab\n","from nbutils import git as nb_git\n","from nbutils import exec as nb_exec\n","from nbutils import data as nb_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6888,"status":"ok","timestamp":1703326583765,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"iaURjw5n6pLq","outputId":"5c40ee52-1fa3-44df-a94e-b81bec144100"},"outputs":[],"source":["# Install requirements in the current Jupyter kernel\n","req_file = os.path.join(package_path, \"requirements.txt\")\n","nb_reqs.pip_install_reqs(req_file, on_colab)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1703326583765,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"iRERDI8aAnzr"},"outputs":[],"source":["# Now we should be able to import the additional packages\n","import mlx \n","import mlx.core as mx\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Set the random seed for reproducibility\n","mx.random.seed(42)"]},{"cell_type":"markdown","metadata":{"id":"_aI-pchqASeB"},"source":["## MLX\n","\n","MLX provides composable function transformations, supporting automatic differentiation, automatic vectorization, and optimization of computation graphs. Computation graphs within MLX are dynamically constructed. A key feature of MLX is the use of (and optimization for) unified memory present in the Apple SoCs. \n","\n","See:\n","- https://github.com/ml-explore/mlx\n","- https://ml-explore.github.io/mlx/build/html/quick_start.html"]},{"cell_type":"markdown","metadata":{"id":"aUACL9QoFTXg"},"source":["## Linear regression"]},{"cell_type":"markdown","metadata":{},"source":["### Create some data based on adding noise to a known linear function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating a function f(x) with a slope of 2 and bias of 1, e.g. f(x) = 2x + 1\n","# and added Gaussian noise\n","\n","# True parameters\n","w_true = 2\n","b_true = 1\n","params_true = mx.array([w_true, b_true])\n","\n","X = mx.arange(-5, 5, 0.1)\n","Y = w_true*X + b_true + 2 * mx.random.normal(X.shape)\n","\n","# Visualize\n","plt.scatter(X, Y, alpha=0.5)\n","plt.title(\"Scatter plot of f(x) = 2x + 1 + Gaussian noise\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Linear model and loss\n","\n","Our linear regression model is $ y = f(x) = w \\cdot x + b$. We solve for $w$ and $b$ using gradient descent. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def lin_model(params, x):\n","    w,b = params\n","    return w*x + b"]},{"cell_type":"markdown","metadata":{},"source":["We uses mean squared error loss between the predictions of our model and true values. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def loss_fn(params, x, y):\n","    y_pred = lin_model(params, x)\n","    return mx.mean(mx.square(y - y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["### Optimization via gradient descent"]},{"cell_type":"markdown","metadata":{},"source":["Initialize parameters $w$ and $b$ randomly."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["params = 1e-2 * mx.random.normal((2,))\n","w,b = params\n","print(f\"Initial weight : {w}\")\n","print(f\"Initial bias   : {b}\")"]},{"cell_type":"markdown","metadata":{},"source":["Optimize via gradient descent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hyperparameters\n","num_iters = 10000\n","learning_rate = 3e-4\n","\n","# Function that computes loss and its gradient\n","loss_and_grad_fn = mx.value_and_grad(loss_fn)\n","\n","# Loop over the number of iterations\n","for it in range(num_iters):\n","\n","    # gradient of loss function (vectorized)\n","    loss, loss_grad = loss_and_grad_fn(params, X, Y)\n","\n","    # update parameters via gradient descent update rules\n","    params -= learning_rate * loss_grad\n","\n","    # Evaluate the parameters explicitly, because MLX uses lazy evaluation\n","    mx.eval(params)\n","\n","    # Give some status output once in a while\n","    if it % 500 == 0 or it == num_iters - 1:\n","        w,b = params  \n","        error_norm = mx.sum(mx.square(params - params_true)) ** 0.5\n","        print(f\"Iteration {it:5d} | Loss {loss.item():>10.5f} | \" \n","              f\"w {w.item():> 8.5f} | b {b.item():> 8.5f} | Error norm {error_norm.item():>.5f}\")\n","\n","\n","    \n","w,b = params    \n","print(f\"Final weight after optimization : {w.item():.5f} (true: {w_true})\")\n","print(f\"Final bias after optimization   : {b.item():.5f} (true: {b_true})\")       "]},{"cell_type":"markdown","metadata":{},"source":["Visualize linear fit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize\n","plt.scatter(X, Y, alpha=0.5)\n","plt.title(\"Scatter plot of f(x) = 2x + 1 + Gaussian noise\")\n","\n","# Plot the recovered line\n","Y_model = lin_model(params, X)\n","plt.plot(X.tolist(), Y_model.tolist(), color='red')\n","\n","plt.legend([\"data\", f\"f(x) = {w.item():.3f}x + {b.item():.3f}\"])\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["JcF1mpJo-taz"],"provenance":[]},"kernelspec":{"display_name":"mlx-m1-2023-12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
