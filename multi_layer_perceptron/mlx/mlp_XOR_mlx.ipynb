{"cells":[{"cell_type":"markdown","metadata":{"id":"epxcwtWj5yJs"},"source":["# Multi-Layer Perceptron for the XOR problem in MLX\n","\n","Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n","\n","This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."]},{"cell_type":"markdown","metadata":{},"source":["We build and train a perceptron to act as a simple XOR gate with two inputs and one output. \n","XOR gates have the following behavior:\n","\n","If both inputs are identical, the output is 0 (off)\n","If both inputs are different, the output is 1 (on)\n","\n","| observation # | input 1 | input 2 | output |\n","|---------------|---------|---------|--------|\n","| 0             | 0       | 0       | 0      |\n","| 1             | 0       | 1       | 1      |\n","| 2             | 1       | 0       | 1      |\n","| 3             | 1       | 1       | 0      |"]},{"cell_type":"markdown","metadata":{},"source":["\n","**Note: This requires a machine with an Apple SoC, e.g. M1/M2/M3 etc.**\n","\n","See: https://github.com/ml-explore/mlx"]},{"cell_type":"markdown","metadata":{"id":"IJsjl_l47q28"},"source":["## Setup\n","\n","Adapt `packagePath` to point to the directory containing this notebeook."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1703326573912,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"1iHkPBml98YG"},"outputs":[],"source":["# Imports\n","import sys\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2602,"status":"ok","timestamp":1703326576880,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"DY4880S378_F","outputId":"a8ce2d26-fe24-4aa2-c232-acc31b71d394"},"outputs":[{"name":"stdout","output_type":"stream","text":["Package path: ./\n"]}],"source":["# Package Path\n","package_path = \"./\" # local\n","print(f\"Package path: {package_path}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6888,"status":"ok","timestamp":1703326583765,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"iaURjw5n6pLq","outputId":"5c40ee52-1fa3-44df-a94e-b81bec144100"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: mlx in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from -r ./requirements.txt (line 1)) (0.0.6)\n","Requirement already satisfied: numpy in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from -r ./requirements.txt (line 2)) (1.26.2)\n","Requirement already satisfied: matplotlib in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from -r ./requirements.txt (line 3)) (3.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (23.2)\n","Requirement already satisfied: pillow>=8 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (10.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from matplotlib->-r ./requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /Users/menzweil/Development/miniforge3/envs/mlx-m1-2023-12/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r ./requirements.txt (line 3)) (1.16.0)\n"]}],"source":["# Install requirements in the current Jupyter kernel\n","req_file = os.path.join(package_path, \"requirements.txt\")\n","if os.path.exists(req_file):\n","    !{sys.executable} -m pip install -r {req_file}\n","else:\n","    print(f\"Requirements file not found: {req_file}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1703326583765,"user":{"displayName":"Markus Enzweiler","userId":"04524044579212347608"},"user_tz":-60},"id":"iRERDI8aAnzr"},"outputs":[],"source":["# Now we should be able to import the additional packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import mlx\n","import mlx.core as mx\n","import mlx.nn as nn\n","import mlx.optimizers as optim\n","\n","# Set the random seed for reproducibility\n","np.random.seed(42)\n","mx.random.seed(42)\n"]},{"cell_type":"markdown","metadata":{"id":"aUACL9QoFTXg"},"source":["## Create the training data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data X with labels y:\n","array([0, 0], dtype=float32) -> array(0, dtype=float32)\n","array([0, 1], dtype=float32) -> array(1, dtype=float32)\n","array([1, 0], dtype=float32) -> array(1, dtype=float32)\n","array([1, 1], dtype=float32) -> array(0, dtype=float32)\n"]}],"source":["# Define the training data for the OR problem in numpy\n","\n","\n","# Define the training data for the OR problem\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","Y = np.array([0, 1, 1, 0])\n","\n","# Convert numpy arrays to mlx tensors\n","X = mx.array(X, dtype=mx.float32)\n","Y = mx.array(Y, dtype=mx.float32)\n","\n","print(\"Training data X with labels y:\")\n","for i in range(len(X)):\n","    print(f\"{X[i]} -> {Y[i]}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Define the Multi-Layer Perceptron (MLP)"]},{"cell_type":"markdown","metadata":{},"source":["## MLP class"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class MultiLayerPerceptron(nn.Module):\n","    # override constructor from nn.Module\n","    def __init__(self, num_inputs, num_hidden_layer_neurons=2):\n","        super().__init__() ## call constructor of nn.Module\n","\n","        # layer 1 defines the transformation from input to hidden layer\n","        self.layer1 = nn.Linear(input_dims=num_inputs, output_dims=num_hidden_layer_neurons)\n","        # layer 2 defines the transformation from hidden layer to output\n","        self.layer2 = nn.Linear(input_dims=num_hidden_layer_neurons, output_dims=1)\n","        self.sigmoid = mx.sigmoid\n","\n","    def __call__(self, x):\n","        return self.forward(x)\n","\n","    def forward(self, x):\n","        # x (input) -> hidden layer -> sigmoid -> output layer -> sigmoid\n","        x = self.sigmoid(self.layer1(x))\n","        x = self.sigmoid(self.layer2(x))\n","        return x        \n","\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# MLP training with gradient descent"]},{"cell_type":"markdown","metadata":{},"source":["## Training and testing functions"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Training function\n","def train(model, X, Y, optimizer, loss_and_grad_fn, num_epochs):\n","\n","    #  Loop over epochs\n","    for epoch in range(num_epochs):\n","\n","        # Reset accumulated loss per epoch\n","        acc_loss = 0\n","\n","        # Loop over all training data\n","        for i in range(len(X)):          \n","        \n","            # forward and backward pass\n","            loss, gradients = loss_and_grad_fn(model, X[i], Y[i].reshape(1,))     \n","            acc_loss += loss\n","\n","            # Update the model with the gradients. So far no computation has happened.\n","            optimizer.update(model, gradients)\n","\n","            # Compute the new parameters and also the new optimizer state.\n","            mx.eval(model.parameters(), optimizer.state)\n","        \n","\n","        # Print accumulated average loss per epoch once in a while\n","        if (epoch % (num_epochs//10)) == 0 or epoch == num_epochs - 1:     \n","            print(f\"Epoch {epoch:5d}: loss = {mx.mean(acc_loss).item():.5f}\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Testing function\n","def test(model, X, Y):\n","    # test the model on all data points\n","    print(\"Testing ...\")\n","    for i in range(len(X)):\n","        prediction = model(X[i])\n","        print(f\"{X[i]} -> {prediction} (label: {Y[i]})\")"]},{"cell_type":"markdown","metadata":{},"source":["## Train and test"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'perceptron' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mmse_loss((model(X)), y)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create the gradient function\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m loss_and_grad_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mvalue_and_grad(\u001b[43mperceptron\u001b[49m, loss_fn)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Stochastic gradient descent (SGD) optimizer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39meta)\n","\u001b[0;31mNameError\u001b[0m: name 'perceptron' is not defined"]}],"source":["# Perceptron for our OR problem\n","model = MultiLayerPerceptron(num_inputs=2)\n","# Evaluate because mlx uses lazy evaluation\n","mx.eval(model.parameters())\n","\n","# Hyperparameters\n","num_epochs = 10000\n","eta = 0.25\n","\n","# Loss function\n","def loss_fn(model, X, y):  \n","    return nn.losses.mse_loss((model(X)), y)\n","\n","# Create the gradient function\n","loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n","\n","# Stochastic gradient descent (SGD) optimizer\n","optimizer = optim.SGD(learning_rate=eta)\n","\n","# Train the model\n","train(model, X, Y, optimizer, loss_and_grad_fn, num_epochs)\n","\n","# Test the model\n","test(model, X, Y)"]},{"cell_type":"markdown","metadata":{},"source":["# Visualize decision boundary"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.cm as cm\n","import matplotlib.gridspec as gridspec\n","\n","\n","def show_decision_boundary(model, data, labels, subplot_spec=None):\n","\n","    data   = np.array(data)\n","    labels = np.array(labels)\n","\n","    wratio = (15, 1)\n","    if subplot_spec is None:\n","        gs = gridspec.GridSpec(1, 2, width_ratios=wratio)\n","    else:\n","        gs = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=subplot_spec, width_ratios=wratio)\n","        \n","    ax = plt.subplot(gs[0])\n","    ax.set_title('Dataset and decision function')\n","    \n","    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n","    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n","    h = 0.01  # Reduced step size for higher resolution\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","\n","    Z = model(mx.array(np.c_[xx.ravel(), yy.ravel()], dtype=mx.float32))\n","    Z = Z.reshape(xx.shape)\n","    \n","\n","    # Increase the number of levels for smoother color transitions\n","    levels = np.linspace(0, 1, 100)\n","    ctr = ax.contourf(xx, yy, np.array(Z), levels, cmap=cm.gray, vmin=0, vmax=1)\n","    \n","    unique_labels = np.unique(labels)\n","\n","    # Define colors for each class\n","    colors = ['red', 'blue']\n","    for i, yi in enumerate(unique_labels):\n","        color = colors[i]\n","        ax.scatter(data[np.where(labels.flatten() == yi), 0], data[np.where(labels.flatten() == yi), 1], \n","                   color=color, linewidth=0, label='Class %d (y=%d)' % (yi, yi))\n","    ax.legend()\n","    ax.set_xlim((x_min, x_max))\n","    ax.set_ylim((y_min, y_max))\n","\n","    # Create colorbar\n","    cbar = plt.colorbar(ctr, cax=plt.subplot(gs[1]))\n","    cbar.set_ticks(np.arange(0, 1.1, 0.1))  # Set ticks from 0 to 1 with 0.1 increments\n","    cbar.set_label('Decision value')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot decision boundary\n","show_decision_boundary(perceptron, X, Y)"]}],"metadata":{"colab":{"collapsed_sections":["JcF1mpJo-taz"],"provenance":[]},"kernelspec":{"display_name":"mlx-m1-2023-12","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
