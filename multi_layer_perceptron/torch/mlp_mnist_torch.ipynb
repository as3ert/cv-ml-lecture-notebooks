{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epxcwtWj5yJs"
   },
   "source": [
    "# Multi-Layer Perceptron for MNIST image classification in PyTorch\n",
    "\n",
    "Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n",
    "\n",
    "This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build and train a multi-layer perceptron (MLP) to classify MNIST digits (https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://pytorch.org/docs/stable/nn.html and in particular:\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html  \n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.Linear.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJsjl_l47q28"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Adapt `packagePath` to point to the directory containing this notebeook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1703326573912,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "1iHkPBml98YG"
   },
   "outputs": [],
   "source": [
    "# Notebook id\n",
    "nb_id = \"multi_layer_perceptron/torch\"\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Path (folder of this notebook)\n",
    "\n",
    "#####################\n",
    "# Local environment #\n",
    "#####################\n",
    "\n",
    "package_path = \"./\"\n",
    "\n",
    "\n",
    "#########\n",
    "# Colab #\n",
    "#########\n",
    "\n",
    "\n",
    "def check_for_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# running on Colab?\n",
    "on_colab = check_for_colab()\n",
    "\n",
    "if on_colab:\n",
    "    # assume this notebook is run from Google Drive and the whole\n",
    "    # cv-ml-lecture-notebooks repo has been setup via setupOnColab.ipynb\n",
    "\n",
    "    # Google Drive mount point\n",
    "    gdrive_mnt = \"/content/drive\"\n",
    "\n",
    "    ##########################################################################\n",
    "    # Ensure that this is the same as gdrive_repo_root in setupOnColab.ipynb #\n",
    "    ##########################################################################\n",
    "    # Path on Google Drive to the cv-ml-lecture-notebooks repo\n",
    "    gdrive_repo_root = f\"{gdrive_mnt}/MyDrive/cv-ml-lecture-notebooks\"\n",
    "\n",
    "    # mount drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(gdrive_mnt, force_remount=True)\n",
    "\n",
    "    # set package path\n",
    "    package_path = f\"{gdrive_repo_root}/{nb_id}\"\n",
    "\n",
    "# check whether package path exists\n",
    "if not os.path.isdir(package_path):\n",
    "    raise FileNotFoundError(f\"Package path does not exist: {package_path}\")\n",
    "\n",
    "print(f\"Package path: {package_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2602,
     "status": "ok",
     "timestamp": 1703326576880,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "DY4880S378_F",
    "outputId": "a8ce2d26-fe24-4aa2-c232-acc31b71d394"
   },
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "\n",
    "# Repository Root\n",
    "repo_root = os.path.abspath(os.path.join(package_path, \"..\", \"..\"))\n",
    "# Add the repository root to the system path\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "# Package Imports\n",
    "from nbutils import requirements as nb_reqs\n",
    "from nbutils import colab as nb_colab\n",
    "from nbutils import git as nb_git\n",
    "from nbutils import exec as nb_exec\n",
    "from nbutils import data as nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6888,
     "status": "ok",
     "timestamp": 1703326583765,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "iaURjw5n6pLq",
    "outputId": "5c40ee52-1fa3-44df-a94e-b81bec144100"
   },
   "outputs": [],
   "source": [
    "# Install requirements in the current Jupyter kernel\n",
    "req_file = os.path.join(package_path, \"requirements.txt\")\n",
    "nb_reqs.pip_install_reqs(req_file, on_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1703326583765,
     "user": {
      "displayName": "Markus Enzweiler",
      "userId": "04524044579212347608"
     },
     "user_tz": -60
    },
    "id": "iRERDI8aAnzr"
   },
   "outputs": [],
   "source": [
    "# Now we should be able to import the additional packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically select a good (GPU) device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the devices that we have available and prefer CUDA over MPS and CPU\n",
    "def autoselectDevice(verbose=0):\n",
    "    # default: CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # CUDA\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        # MPS (acceleration on Apple silicon M1 / M2 chips)\n",
    "        device = torch.device(\"mps\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Using device:\", device)\n",
    "\n",
    "    # Additional Info when using cuda\n",
    "    if verbose and device.type == \"cuda\":\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "device = autoselectDevice(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUACL9QoFTXg"
   },
   "source": [
    "## Load the MNIST training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset using torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the pixel data to 0-1 range\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load the training data\n",
    "train_set = datasets.MNIST(\"./data\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(\"./data\", download=True, train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some samples and class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "\n",
    "(data, target) = next(iter(train_loader))\n",
    "\n",
    "# extract image size (height and width)\n",
    "image_height = data.size(2)\n",
    "image_width = data.size(3)\n",
    "image_size = (image_height, image_width)\n",
    "\n",
    "print(f\"MNIST images have size {image_height}x{image_width}\")\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(data[i, :, :, :].numpy().reshape(image_size), cmap=\"gray\")\n",
    "    plt.title(\"Label: \" + str(target[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer perceptron model\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # number of input neurons = number of pixels in the image, i.e. 28x28 = 784\n",
    "        # number of hidden layer 1 neurons = 20 (arbitrary choice)\n",
    "        # number of hidden layer 2 neurons = 30 (arbitrary choice)\n",
    "        # number of output neurons = 10 (one for each digit class)\n",
    "\n",
    "        # layer 1 defines the transformation from input to hidden layer 1\n",
    "        self.layer1 = nn.Linear(28 * 28, 20)\n",
    "        # layer 2 defines the transformation from hidden layer 1 to hidden layer 2\n",
    "        self.layer2 = nn.Linear(20, 30)\n",
    "        # layer 3 defines the transformation from hidden layer to output\n",
    "        self.layer3 = nn.Linear(30, 10)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (input) -> hidden layer -> sigmoid -> output layer -> sigmoid\n",
    "        x = x.view(\n",
    "            -1, 28 * 28\n",
    "        )  # flatten the 28x28 input image to a 768-dimensional vector\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        # \"softmax\" activation will be automatically applied in the cross entropy loss below,\n",
    "        # see https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "def compute_accuracy(outputs, labels):\n",
    "    # find predicted labels (the output neuron index with the highest output value)\n",
    "    _, predicted_labels = torch.max(outputs, 1)\n",
    "    return torch.sum(predicted_labels == labels)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, loss_fn, num_epochs):\n",
    "    # push the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # number of training samples in total\n",
    "        num_train_samples = len(train_loader.dataset)\n",
    "\n",
    "        # number of batches\n",
    "        num_batches = len(train_loader)\n",
    "\n",
    "        # reset accumulated loss and accuracy\n",
    "        acc_loss = 0.0\n",
    "        num_correct = 0.0\n",
    "\n",
    "        # loop over data samples in batches\n",
    "        for data in train_loader:\n",
    "            # training sample and label\n",
    "            x, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_hat = model(x)\n",
    "\n",
    "            # backward pass\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "\n",
    "            # accumulate loss\n",
    "            acc_loss += loss\n",
    "\n",
    "            # Update weights and bias\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute current accuracy and accumulate\n",
    "            num_correct += compute_accuracy(y_hat, y)\n",
    "\n",
    "        # average loss and accuracy per epoch\n",
    "        avg_loss = acc_loss / num_batches\n",
    "        accuracy = num_correct / num_train_samples\n",
    "\n",
    "        # Print accumulated average loss per epoch\n",
    "        print(\n",
    "            f\"Epoch {epoch:5d}: loss = {avg_loss:.5f}, accuracy on training set = {100 * accuracy:.2f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    # test the model on all data points\n",
    "    print(\"Testing ...\")\n",
    "\n",
    "    num_correct = 0\n",
    "    test_size = len(test_loader.dataset)\n",
    "\n",
    "    # push the model to the device\n",
    "    model.to(device)\n",
    "\n",
    "    for data in test_loader:\n",
    "        x, y = data[0].to(device), data[1].to(device)\n",
    "        prediction = model(x)\n",
    "\n",
    "        # compute and accumulate accuracy\n",
    "        num_correct += compute_accuracy(prediction, y)\n",
    "\n",
    "    # Print accuracy\n",
    "    print(f\"Accuracy: {num_correct}/{test_size} = {100 * num_correct/test_size:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MLP model\n",
    "\n",
    "# The model to train\n",
    "model = MultiLayerPerceptron()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 5\n",
    "eta = 1e-4\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
    "\n",
    "# We use cross-entropy loss for classification problems\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, optimizer, loss_fn, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and visualize some predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell multiple times to see some more predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run some predictions on the test set\n",
    "\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "\n",
    "# get next test data\n",
    "(data, target) = next(test_iter)\n",
    "data, target = data.to(device), target.to(device)\n",
    "\n",
    "# forward pass\n",
    "predictions = model(data)\n",
    "# find predicted labels (the output neuron index with the highest output value)\n",
    "_, predicted_labels = torch.max(predictions, 1)\n",
    "\n",
    "# extract image size (height and width)\n",
    "image_height = data.size(2)\n",
    "image_width = data.size(3)\n",
    "image_size = (image_height, image_width)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(data[i, :, :, :].cpu().numpy().reshape(image_size), cmap=\"gray\")\n",
    "    plt.title(\"Pred.: \" + str(predicted_labels[i].item()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JcF1mpJo-taz"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlx-pytorch-2024-01",
   "language": "python",
   "name": "mlx-pytorch-2024-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
