{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Deep Generative Adversarial Networks (DCGAN) using PyTorch\n",
    "\n",
    "Author: [Markus Enzweiler](https://markus-enzweiler-de), markus.enzweiler@hs-esslingen.de\n",
    "\n",
    "This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See `gan_torch_mnist.ipynb` for a more in-depth notebook on GANs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Adapt `packagePath` to point to the directory containing this notebeook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Path\n",
    "package_path = \"./\" # local\n",
    "print(f\"Package path: {package_path}\")\n",
    "\n",
    "\n",
    "def check_for_colab():\n",
    "  try:\n",
    "      import google.colab\n",
    "      return True\n",
    "  except ImportError:\n",
    "      return False\n",
    "\n",
    "# Running on Colab?\n",
    "on_colab = check_for_colab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone git repository\n",
    "\n",
    "# Absolute path of the repository directory\n",
    "repo_dir = os.path.join(package_path, \"torch-gan\")\n",
    "repo_url = \"https://github.com/menzHSE/torch-gan.git\"\n",
    "\n",
    "# Store the original working directory\n",
    "original_cwd = os.getcwd()\n",
    "\n",
    "# Check if the directory already exists using the absolute path\n",
    "if os.path.exists(os.path.join(original_cwd, repo_dir)):\n",
    "    print(\"Repository exists. Resetting to HEAD...\")\n",
    "    # Navigate into the repository directory\n",
    "    os.chdir(repo_dir)\n",
    "    # Fetch the latest changes from the remote\n",
    "    subprocess.run([\"git\", \"fetch\", \"origin\"])\n",
    "    # Reset the local branch to the latest commit from the remote\n",
    "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/HEAD\"])\n",
    "    # Change back to the original working directory\n",
    "    os.chdir(original_cwd)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    # Clone the repository if it doesn't exist\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n",
    "# Clone git repository\n",
    "\n",
    "# Absolute path of the repository directory\n",
    "repo_dir = os.path.join(package_path, \"torch-gan\")\n",
    "repo_url = \"https://github.com/menzHSE/torch-gan.git\"\n",
    "\n",
    "# Store the original working directory\n",
    "original_cwd = os.getcwd()\n",
    "\n",
    "# Check if the directory already exists using the absolute path\n",
    "if os.path.exists(os.path.join(original_cwd, repo_dir)):\n",
    "    print(\"Repository exists. Resetting to HEAD...\")\n",
    "    # Navigate into the repository directory\n",
    "    os.chdir(repo_dir)\n",
    "    # Fetch the latest changes from the remote\n",
    "    subprocess.run([\"git\", \"fetch\", \"origin\"])\n",
    "    # Reset the local branch to the latest commit from the remote\n",
    "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/HEAD\"])\n",
    "    # Change back to the original working directory\n",
    "    os.chdir(original_cwd)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    # Clone the repository if it doesn't exist\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements in the current Jupyter kernel\n",
    "req_file = os.path.join(repo_dir, \"requirements.txt\")\n",
    "if os.path.exists(req_file):\n",
    "    !{sys.executable} -m pip install -r {req_file}\n",
    "else:\n",
    "    print(f\"Requirements file not found: {req_file}\")\n",
    "\n",
    "\n",
    "# Additional requirements for this notebook\n",
    "req_file = \"requirements.txt\"\n",
    "if os.path.exists(req_file):\n",
    "    !{sys.executable} -m pip install -r {req_file}\n",
    "else:\n",
    "    print(f\"Requirements file not found: {req_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample CelebA faces\n",
    "\n",
    "If the dataset cannot be automatically downloaded by PyTorch due to **daily quota exceeded** you can manually download it and put it in the ```data/celaba``` folder, see code cell below.\n",
    "\n",
    "The following files are necessary:\n",
    "- img_align_celeba.zip\n",
    "- list_attr_celeba.txt\n",
    "- list_bbox_celeba.txt\n",
    "- list_eval_partition.txt\n",
    "- list_landmarks_align_celeba.txt\n",
    "- list_landmarks_celeba.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to download the dataset from an alternative source\n",
    "use_alternative_data_source = True\n",
    "\n",
    "dest_dir = \"./data/celeba\"\n",
    "\n",
    "if use_alternative_data_source:\n",
    "\n",
    "    # Base URL for data\n",
    "    data_url = \"https://graal.ift.ulaval.ca/public/celeba/\"\n",
    "    # Directory to store the files\n",
    "    dest_dir = \"data/celeba\"\n",
    "\n",
    "    # Ensure the destination directory exists\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # List of files to download\n",
    "    celeba_files = [\n",
    "        \"img_align_celeba.zip\",\n",
    "        \"list_attr_celeba.txt\",\n",
    "        \"list_bbox_celeba.txt\",\n",
    "        \"list_eval_partition.txt\",\n",
    "        \"list_landmarks_align_celeba.txt\",\n",
    "        \"list_landmarks_celeba.txt\"\n",
    "    ]\n",
    "\n",
    "    # Download each file using wget with -nc option\n",
    "    for file in celeba_files:\n",
    "        file_url = data_url + file\n",
    "        print(f\"Downloading {file_url} ... \")\n",
    "        !wget -nc {file_url} -P {dest_dir}\n",
    "        print(\"done\")\n",
    "\n",
    "    print(\"Download complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Add the directory containing models.py to the system path\n",
    "sys.path.append(os.path.join(package_path, 'torch-gan'))\n",
    "\n",
    "\n",
    "# Now we can import the model and dataset\n",
    "import model\n",
    "import dataset\n",
    "import device\n",
    "\n",
    "# parameters\n",
    "dataset_id       = \"celeb-a\"\n",
    "num_latent_dims  = 100\n",
    "max_num_filters  = 512\n",
    "img_size         = (64, 64)\n",
    "batch_size       = 32\n",
    "model_id         = f\"G_filters_{max_num_filters:04d}_dims_{num_latent_dims:04d}.pth\"\n",
    "gen_fname        = os.path.join(package_path, \"torch-gan\", \"pretrained\", dataset_id, model_id)\n",
    "dev              = device.autoselectDevice()\n",
    "\n",
    "# load dataset\n",
    "celeba_train_loader, celeba_test_loader, _, celeba_num_img_channels = dataset.get_loaders(\n",
    "    dataset_id, img_size=img_size, batch_size=batch_size)\n",
    "\n",
    "# load the generator\n",
    "G = model.Generator(num_latent_dims, celeba_num_img_channels, max_num_filters, dev)\n",
    "G.load(gen_fname, dev)\n",
    "\n",
    "if G:\n",
    "    print(f\"Model {gen_fname} loaded successfully!\")\n",
    "    print(f\"Device used: {dev}\")\n",
    "    G.to(dev)\n",
    "    G.eval()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeForDisplay(images):\n",
    "    # normalize from [-1, 1] to [0, 1]\n",
    "    return (images + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get a batch of images from the training set and display them\n",
    "# we use the torchvision.utils.make_grid function to create a grid of images\n",
    "images, labels = next(iter(celeba_train_loader))\n",
    "grid_img = torchvision.utils.make_grid(normalizeForDisplay(images), nrow=batch_size//4)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.transpose(grid_img, (1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.title('Batch from the Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CelebA-like Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "def sampleAndPlot(G, num_latent_dims, num_samples=batch_size):\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):         \n",
    "      \n",
    "            # generate a random latent vector   \n",
    "            z = utils.sample_latent_vectors(1, num_latent_dims, dev)\n",
    "\n",
    "            # generate an image from the latent vector\n",
    "            img = G(z)\n",
    "\n",
    "            if i == 0:\n",
    "                pics = img\n",
    "            else:\n",
    "                pics = torch.cat((pics, img), dim=0)\n",
    "\n",
    "          \n",
    "        # Create a grid of images\n",
    "        grid_img = torchvision.utils.make_grid(pics, nrow=batch_size//4)\n",
    "\n",
    "        # Convert grid to numpy and transpose axes for plotting\n",
    "        grid_np = grid_img.cpu().numpy()\n",
    "        grid_np = np.transpose(grid_np, (1, 2, 0))\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(normalizeForDisplay(grid_np))\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Randomly Generated Images from the Generator with {num_latent_dims} Latent Dimensions')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAndPlot(G, num_latent_dims)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-m1-2023-10",
   "language": "python",
   "name": "pytorch-m1-2023-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
