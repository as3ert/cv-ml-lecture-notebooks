{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNN) for CIFAR-10/100 using MLX\n",
    "\n",
    "Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n",
    "\n",
    "This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build and train a CNN for CIFAR-10 / CIFAR-100 image classification, see https://www.cs.toronto.edu/~kriz/cifar.html. We use the Python code from https://github.com/menzHSE/mlx-cifar-10-cnn.git and execute it via this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note: This requires a machine with an Apple SoC, e.g. M1/M2/M3 etc.**\n",
    "\n",
    "See: https://github.com/ml-explore/mlx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Adapt `packagePath` to point to the directory containing this notebeook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import threading\n",
    "import subprocess\n",
    "import fcntl\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Path\n",
    "package_path = \"./\" # local\n",
    "print(f\"Package path: {package_path}\")\n",
    "\n",
    "\n",
    "def check_for_colab():\n",
    "  try:\n",
    "      import google.colab\n",
    "      return True\n",
    "  except ImportError:\n",
    "      return False\n",
    "\n",
    "# Running on Colab?\n",
    "on_colab = check_for_colab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone git repository\n",
    "\n",
    "# Absolute path of the repository directory\n",
    "repo_dir = os.path.join(package_path, \"mlx-cifar-10-cnn\")\n",
    "repo_url = \"https://github.com/menzHSE/mlx-cifar-10-cnn.git\"\n",
    "\n",
    "# Store the original working directory\n",
    "original_cwd = os.getcwd()\n",
    "\n",
    "# Check if the directory already exists using the absolute path\n",
    "if os.path.exists(os.path.join(original_cwd, repo_dir)):\n",
    "    print(\"Repository exists. Resetting to HEAD...\")\n",
    "    # Navigate into the repository directory\n",
    "    os.chdir(repo_dir)\n",
    "    # Fetch the latest changes from the remote\n",
    "    subprocess.run([\"git\", \"fetch\", \"origin\"])\n",
    "    # Reset the local branch to the latest commit from the remote\n",
    "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/HEAD\"])\n",
    "    # Change back to the original working directory\n",
    "    os.chdir(original_cwd)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    # Clone the repository if it doesn't exist\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements in the current Jupyter kernel\n",
    "req_file = os.path.join(repo_dir, \"requirements.txt\")\n",
    "if os.path.exists(req_file):\n",
    "    !{sys.executable} -m pip install -r {req_file}\n",
    "else:\n",
    "    print(f\"Requirements file not found: {req_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to interface with the code in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(script_name, params=None):\n",
    "    if on_colab:\n",
    "        executeCaptureColab(script_name, params)\n",
    "    else:\n",
    "        executeCapture(script_name, params)\n",
    "\n",
    "def executeCapture(script_name, params=None):\n",
    "    script_path = os.path.join(repo_dir, script_name)\n",
    "    if os.path.exists(script_path):\n",
    "        print(f\"Executing script: {script_path}\")\n",
    "        # Create the command list starting with Python and the script path\n",
    "        command = [\"python\", script_path]\n",
    "        # Add additional arguments from the params dictionary\n",
    "        if params:\n",
    "            for key, value in params.items():\n",
    "                command.append(f\"--{key}\")\n",
    "                command.append(str(value))\n",
    "        print(command)\n",
    "        subprocess.run(command)\n",
    "    else:\n",
    "        print(f\"Script not found: {script_path}\")\n",
    "\n",
    "# This is very hacky ... but it's hard to capture the output of a subprocess in Colab\n",
    "def executeCaptureColab(script_name, params=None):\n",
    "    script_path = os.path.join(repo_dir, script_name)\n",
    "    if os.path.exists(script_path):\n",
    "        print(f\"Executing script: {script_path}\")\n",
    "        # Create the command list starting with Python and the script path\n",
    "        command = [\"python\", script_path]\n",
    "        # Add additional arguments from the params dictionary\n",
    "        if params:\n",
    "            for key, value in params.items():\n",
    "                if value is not None:  # Check if the value is None\n",
    "                    command.append(f\"--{key}\")\n",
    "                    command.append(str(value))\n",
    "                else:\n",
    "                    command.append(f\"--{key}\")\n",
    "        print(\"Command:\", \" \".join(command))\n",
    "\n",
    "        # Start the subprocess\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "        # Set the stdout to non-blocking\n",
    "        fd = process.stdout.fileno()\n",
    "        fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n",
    "        fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n",
    "\n",
    "        # Function to continuously output lines from a stream\n",
    "        def stream_output(stream):\n",
    "            while True:\n",
    "                try:\n",
    "                    line = stream.readline()\n",
    "                    if line:\n",
    "                        print(line, end='')\n",
    "                    elif process.poll() is not None:\n",
    "                        break\n",
    "                except IOError as e:\n",
    "                    # Ignore the error if no data is available yet\n",
    "                    if e.errno != errno.EAGAIN and e.errno != errno.EWOULDBLOCK:\n",
    "                        raise\n",
    "\n",
    "        # Use a thread to capture the output stream\n",
    "        output_thread = threading.Thread(target=stream_output, args=(process.stdout,))\n",
    "        output_thread.start()\n",
    "\n",
    "        # Wait for the subprocess to complete and the output thread to end\n",
    "        process.wait()\n",
    "        output_thread.join()\n",
    "\n",
    "    else:\n",
    "        print(f\"Script not found: {script_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we can do with train.py\n",
    "execute(\"train.py\", {\"help\": None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test CNN on CIFAR-10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed      = 42\n",
    "lr        = 3e-4\n",
    "epochs    = 30\n",
    "dataset   = \"CIFAR-10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,           # dataset name\n",
    "    \"batchsize\": batchsize,       # batch size\n",
    "    \"seed\": seed,                 # random seed\n",
    "    \"lr\": lr,                     # learning rate\n",
    "    \"epochs\": epochs              # number of epochs\n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"train.py\", params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"model\": f\"models/model_{dataset}_{epochs-1:03d}.npz\" # model name    \n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"test.py\", params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test CNN on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed      = 42\n",
    "lr        = 3e-4\n",
    "epochs    = 30\n",
    "dataset   = \"CIFAR-100\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,           # dataset name\n",
    "    \"batchsize\": batchsize,       # batch size\n",
    "    \"seed\": seed,                 # random seed\n",
    "    \"lr\": lr,                     # learning rate\n",
    "    \"epochs\": epochs              # number of epochs\n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"train.py\", params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"dataset\": dataset,           # dataset name\n",
    "    \"model\": f\"models/model_{dataset}_{epochs-1:03d}.npz\" # model name    \n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"test.py\", params=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-m1-2023-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
