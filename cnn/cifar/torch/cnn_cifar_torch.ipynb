{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNN) for CIFAR-10/100 using PyTorch\n",
    "\n",
    "Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n",
    "\n",
    "This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build and train a CNN for CIFAR-10 / CIFAR-100 image classification, see https://www.cs.toronto.edu/~kriz/cifar.html. We use the Python code from https://github.com/menzHSE/torch-cifar-10-cnn.git and execute it via this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Adapt `packagePath` to point to the directory containing this notebeook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook id\n",
    "nb_id = \"cnn/cifar/torch\"\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Path (folder of this notebook)\n",
    "\n",
    "#####################\n",
    "# Local environment #\n",
    "#####################\n",
    "\n",
    "package_path = \"./\"\n",
    "\n",
    "\n",
    "#########\n",
    "# Colab #\n",
    "#########\n",
    "\n",
    "\n",
    "def check_for_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# running on Colab?\n",
    "on_colab = check_for_colab()\n",
    "\n",
    "if on_colab:\n",
    "    # assume this notebook is run from Google Drive and the whole\n",
    "    # cv-ml-lecture-notebooks repo has been setup via setupOnColab.ipynb\n",
    "\n",
    "    # Google Drive mount point\n",
    "    gdrive_mnt = \"/content/drive\"\n",
    "\n",
    "    ##########################################################################\n",
    "    # Ensure that this is the same as gdrive_repo_root in setupOnColab.ipynb #\n",
    "    ##########################################################################\n",
    "    # Path on Google Drive to the cv-ml-lecture-notebooks repo\n",
    "    gdrive_repo_root = f\"{gdrive_mnt}/MyDrive/cv-ml-lecture-notebooks\"\n",
    "\n",
    "    # mount drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(gdrive_mnt, force_remount=True)\n",
    "\n",
    "    # set package path\n",
    "    package_path = f\"{gdrive_repo_root}/{nb_id}\"\n",
    "\n",
    "# check whether package path exists\n",
    "if not os.path.isdir(package_path):\n",
    "    raise FileNotFoundError(f\"Package path does not exist: {package_path}\")\n",
    "\n",
    "print(f\"Package path: {package_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "\n",
    "# Repository Root\n",
    "repo_root = os.path.abspath(os.path.join(package_path, \"..\", \"..\", \"..\"))\n",
    "# Add the repository root to the system path\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "# Package Imports\n",
    "from nbutils import requirements as nb_reqs\n",
    "from nbutils import colab as nb_colab\n",
    "from nbutils import git as nb_git\n",
    "from nbutils import exec as nb_exec\n",
    "from nbutils import data as nb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone git repository\n",
    "\n",
    "# Absolute path of the repository directory\n",
    "repo_dir = os.path.join(package_path, \"torch-cifar-10-cnn\")\n",
    "repo_url = \"https://github.com/menzHSE/torch-cifar-10-cnn.git\"\n",
    "\n",
    "nb_git.clone(repo_url, repo_dir, on_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements in the current Jupyter kernel\n",
    "req_file = os.path.join(repo_dir, \"requirements.txt\")\n",
    "nb_reqs.pip_install_reqs(req_file, on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test CNN on CIFAR-10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we can do with train.py\n",
    "nb_exec.executePythonScript(\n",
    "    os.path.join(repo_dir, \"train.py\"), {\"help\": None}, on_colab\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed = 42\n",
    "lr = 3e-4\n",
    "epochs = 30\n",
    "dataset = \"CIFAR-10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,  # dataset name\n",
    "    \"batchsize\": batchsize,  # batch size\n",
    "    \"seed\": seed,  # random seed\n",
    "    \"lr\": lr,  # learning rate\n",
    "    \"epochs\": epochs,  # number of epochs\n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "nb_exec.executePythonScript(os.path.join(repo_dir, \"train.py\"), params, on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\"model\": f\"models/model_{dataset}_{epochs-1:03d}.pth\"}  # model name\n",
    "\n",
    "# Execute 'test.py' with parameters\n",
    "nb_exec.executePythonScript(os.path.join(repo_dir, \"test.py\"), params, on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test CNN on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed = 42\n",
    "lr = 3e-4\n",
    "epochs = 30\n",
    "dataset = \"CIFAR-100\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,  # dataset name\n",
    "    \"batchsize\": batchsize,  # batch size\n",
    "    \"seed\": seed,  # random seed\n",
    "    \"lr\": lr,  # learning rate\n",
    "    \"epochs\": epochs,  # number of epochs\n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "nb_exec.executePythonScript(os.path.join(repo_dir, \"train.py\"), params, on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"dataset\": dataset,  # dataset name\n",
    "    \"model\": f\"models/model_{dataset}_{epochs-1:03d}.pth\",  # model name\n",
    "}\n",
    "\n",
    "# Execute 'test.py' with parameters\n",
    "nb_exec.executePythonScript(os.path.join(repo_dir, \"test.py\"), params, on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune a ResNet on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed = 42\n",
    "lr = 3e-4\n",
    "epochs = 5\n",
    "dataset = \"CIFAR-100\"\n",
    "finetune = \"resnet18\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,  # dataset name\n",
    "    \"batchsize\": batchsize,  # batch size\n",
    "    \"seed\": seed,  # random seed\n",
    "    \"lr\": lr,  # learning rate\n",
    "    \"epochs\": epochs,  # number of epochs\n",
    "    \"finetune\": finetune,  # finetune model\n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "nb_exec.executePythonScript(os.path.join(repo_dir, \"train.py\"), params, on_colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"dataset\": dataset,  # dataset name\n",
    "    \"model\": f\"models/model_{finetune}_{dataset}_{epochs-1:03d}.pth\",  # model name\n",
    "    \"finetune\": finetune,  # finetune model\n",
    "}\n",
    "\n",
    "# Execute 'test.py' with parameters\n",
    "nb_exec.executePythonScript(os.path.join(repo_dir, \"test.py\"), params, on_colab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-m1-2023-10",
   "language": "python",
   "name": "pytorch-m1-2023-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
