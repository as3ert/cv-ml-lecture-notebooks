{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNN) for CIFAR-10/100 using PyTorch\n",
    "\n",
    "Markus Enzweiler, markus.enzweiler@hs-esslingen.de\n",
    "\n",
    "This is a demo used in a Computer Vision & Machine Learning lecture. Feel free to use and contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build and train a CNN for CIFAR-10 / CIFAR-100 image classification, see https://www.cs.toronto.edu/~kriz/cifar.html. We use the Python code from https://github.com/menzHSE/torch-cifar-10-cnn.git and execute it via this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Adapt `packagePath` to point to the directory containing this notebeook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package path: ./\n"
     ]
    }
   ],
   "source": [
    "# Package Path\n",
    "package_path = \"./\" # local\n",
    "print(f\"Package path: {package_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository exists. Resetting to HEAD...\n",
      "HEAD is now at 11e6d3f Update README.md\n"
     ]
    }
   ],
   "source": [
    "# Clone git repository\n",
    "\n",
    "# Absolute path of the repository directory\n",
    "repo_dir = os.path.join(package_path, \"torch-cifar-10-cnn\")\n",
    "repo_url = \"https://github.com/menzHSE/torch-cifar-10-cnn.git\"\n",
    "\n",
    "# Store the original working directory\n",
    "original_cwd = os.getcwd()\n",
    "\n",
    "# Check if the directory already exists using the absolute path\n",
    "if os.path.exists(os.path.join(original_cwd, repo_dir)):\n",
    "    print(\"Repository exists. Resetting to HEAD...\")\n",
    "    # Navigate into the repository directory\n",
    "    os.chdir(repo_dir)\n",
    "    # Fetch the latest changes from the remote\n",
    "    subprocess.run([\"git\", \"fetch\", \"origin\"])\n",
    "    # Reset the local branch to the latest commit from the remote\n",
    "    subprocess.run([\"git\", \"reset\", \"--hard\", \"origin/HEAD\"])\n",
    "    # Change back to the original working directory\n",
    "    os.chdir(original_cwd)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    # Clone the repository if it doesn't exist\n",
    "    subprocess.run([\"git\", \"clone\", repo_url, repo_dir])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from -r ./torch-cifar-10-cnn/requirements.txt (line 1)) (1.13.0.dev20220627)\n",
      "Requirement already satisfied: torchvision in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from -r ./torch-cifar-10-cnn/requirements.txt (line 2)) (0.14.0.dev20220626)\n",
      "Requirement already satisfied: torchinfo in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from -r ./torch-cifar-10-cnn/requirements.txt (line 3)) (1.7.2)\n",
      "Requirement already satisfied: numpy in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from -r ./torch-cifar-10-cnn/requirements.txt (line 4)) (1.26.0)\n",
      "Requirement already satisfied: Pillow in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from -r ./torch-cifar-10-cnn/requirements.txt (line 5)) (9.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from torch->-r ./torch-cifar-10-cnn/requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: requests in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from torchvision->-r ./torch-cifar-10-cnn/requirements.txt (line 2)) (2.28.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from requests->torchvision->-r ./torch-cifar-10-cnn/requirements.txt (line 2)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from requests->torchvision->-r ./torch-cifar-10-cnn/requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from requests->torchvision->-r ./torch-cifar-10-cnn/requirements.txt (line 2)) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages (from requests->torchvision->-r ./torch-cifar-10-cnn/requirements.txt (line 2)) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "# Install requirements in the current Jupyter kernel\n",
    "req_file = os.path.join(repo_dir, \"requirements.txt\")\n",
    "if os.path.exists(req_file):\n",
    "    !{sys.executable} -m pip install -r {req_file}\n",
    "else:\n",
    "    print(f\"Requirements file not found: {req_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to interface with the code in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(script_name, params=None):\n",
    "    script_path = os.path.join(repo_dir, script_name)\n",
    "    if os.path.exists(script_path):\n",
    "        print(f\"Executing script: {script_path}\")\n",
    "        # Create the command list starting with Python and the script path\n",
    "        command = [\"python\", script_path]\n",
    "        # Add additional arguments from the params dictionary\n",
    "        if params:\n",
    "            for key, value in params.items():\n",
    "                command.append(f\"--{key}\")\n",
    "                command.append(str(value))\n",
    "        print(command)\n",
    "        subprocess.run(command)\n",
    "    else:\n",
    "        print(f\"Script not found: {script_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing script: ./torch-cifar-10-cnn/train.py\n",
      "['python', './torch-cifar-10-cnn/train.py', '--help', 'None']\n",
      "usage: Train a simple CNN on CIFAR-10 / CIFAR_100 with PyTorch.\n",
      "       [-h] [--cpu] [--seed SEED] [--batchsize BATCHSIZE] [--epochs EPOCHS]\n",
      "       [--lr LR] [--dataset {CIFAR-10,CIFAR-100}]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --cpu                 Use CPU instead of GPU (cuda/mps) acceleration\n",
      "  --seed SEED           Random seed\n",
      "  --batchsize BATCHSIZE\n",
      "                        Batch size for training\n",
      "  --epochs EPOCHS       Number of training epochs\n",
      "  --lr LR               Learning rate\n",
      "  --dataset {CIFAR-10,CIFAR-100}\n",
      "                        Select the dataset to use (CIFAR-10 or CIFAR-100)\n"
     ]
    }
   ],
   "source": [
    "# Let's see what we can do with train.py\n",
    "execute(\"train.py\", {\"help\": None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test CNN on CIFAR-10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed      = 42\n",
    "lr        = 3e-4\n",
    "epochs    = 30\n",
    "dataset   = \"CIFAR-10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing script: ./torch-cifar-10-cnn/train.py\n",
      "['python', './torch-cifar-10-cnn/train.py', '--dataset', 'CIFAR-10', '--batchsize', '32', '--seed', '42', '--lr', '0.0003', '--epochs', '30']\n",
      "Using device: mps\n",
      "Options: \n",
      "  Device: GPU\n",
      "  Seed: 42\n",
      "  Batch size: 32\n",
      "  Number of epochs: 30\n",
      "  Learning rate: 0.0003\n",
      "  Dataset: CIFAR-10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type (var_name))                  Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN (CNN)                                [1, 10]                   --\n",
      "├─Conv2d (conv1)                         [1, 32, 32, 32]           896\n",
      "├─Conv2d (conv2)                         [1, 32, 32, 32]           9,248\n",
      "├─MaxPool2d (pool)                       [1, 32, 16, 16]           --\n",
      "├─Dropout (drop)                         [1, 32, 16, 16]           --\n",
      "├─Conv2d (conv3)                         [1, 64, 16, 16]           18,496\n",
      "├─Conv2d (conv4)                         [1, 64, 16, 16]           36,928\n",
      "├─MaxPool2d (pool)                       [1, 64, 8, 8]             --\n",
      "├─Dropout (drop)                         [1, 64, 8, 8]             --\n",
      "├─Conv2d (conv5)                         [1, 128, 8, 8]            73,856\n",
      "├─Conv2d (conv6)                         [1, 128, 8, 8]            147,584\n",
      "├─MaxPool2d (pool)                       [1, 128, 4, 4]            --\n",
      "├─Dropout (drop)                         [1, 128, 4, 4]            --\n",
      "├─Linear (fc1)                           [1, 128]                  262,272\n",
      "├─Linear (fc2)                           [1, 10]                   1,290\n",
      "==========================================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 39.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 2.20\n",
      "Estimated Total Size (MB): 3.13\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type (var_name))                  Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN (CNN)                                [1, 10]                   --\n",
      "├─Conv2d (conv1)                         [1, 32, 32, 32]           896\n",
      "├─Conv2d (conv2)                         [1, 32, 32, 32]           9,248\n",
      "├─MaxPool2d (pool)                       [1, 32, 16, 16]           --\n",
      "├─Dropout (drop)                         [1, 32, 16, 16]           --\n",
      "├─Conv2d (conv3)                         [1, 64, 16, 16]           18,496\n",
      "├─Conv2d (conv4)                         [1, 64, 16, 16]           36,928\n",
      "├─MaxPool2d (pool)                       [1, 64, 8, 8]             --\n",
      "├─Dropout (drop)                         [1, 64, 8, 8]             --\n",
      "├─Conv2d (conv5)                         [1, 128, 8, 8]            73,856\n",
      "├─Conv2d (conv6)                         [1, 128, 8, 8]            147,584\n",
      "├─MaxPool2d (pool)                       [1, 128, 4, 4]            --\n",
      "├─Dropout (drop)                         [1, 128, 4, 4]            --\n",
      "├─Linear (fc1)                           [1, 128]                  262,272\n",
      "├─Linear (fc2)                           [1, 10]                   1,290\n",
      "==========================================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 39.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 2.20\n",
      "Estimated Total Size (MB): 3.13\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch   0] :  ......"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset,           \u001b[38;5;66;03m# dataset name\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchsize\u001b[39m\u001b[38;5;124m\"\u001b[39m: batchsize,       \u001b[38;5;66;03m# batch size\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: epochs              \u001b[38;5;66;03m# number of epochs     \u001b[39;00m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Execute 'train.py' with parameters\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(script_name, params)\u001b[0m\n\u001b[1;32m     11\u001b[0m             command\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(value))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(command)\n\u001b[0;32m---> 13\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScript not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscript_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/subprocess.py:1126\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/subprocess.py:1189\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/subprocess.py:1933\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1933\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/subprocess.py:1891\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1891\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1893\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1894\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1896\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/menzweil/Development/miniforge3/envs/pytorch-m1-2023-10/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 14 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,           # dataset name\n",
    "    \"batchsize\": batchsize,       # batch size\n",
    "    \"seed\": seed,                 # random seed\n",
    "    \"lr\": lr,                     # learning rate\n",
    "    \"epochs\": epochs              # number of epochs     \n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"train.py\", params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"model\": f\"model_{dataset}_{epochs-1:03d}.pth\" # model name    \n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"test.py\", params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test CNN on CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchsize = 32\n",
    "seed      = 42\n",
    "lr        = 3e-4\n",
    "epochs    = 30\n",
    "dataset   = \"CIFAR-100\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\": dataset,           # dataset name\n",
    "    \"batchsize\": batchsize,       # batch size\n",
    "    \"seed\": seed,                 # random seed\n",
    "    \"lr\": lr,                     # learning rate\n",
    "    \"epochs\": epochs              # number of epochs\n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"train.py\", params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = {\n",
    "    \"dataset\": dataset,           # dataset name\n",
    "    \"model\": f\"model_{dataset}_{epochs-1:03d}.pth\" # model name    \n",
    "}\n",
    "\n",
    "# Execute 'train.py' with parameters\n",
    "execute(\"test.py\", params=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-m1-2023-10",
   "language": "python",
   "name": "pytorch-m1-2023-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
